<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Text Generation with First-Order Markov Chain &#8212; CC-MAS 2016 0.1a documentation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1a',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="top" title="CC-MAS 2016 0.1a documentation" href="index.html" />
    <link rel="next" title="Parsing Text with NLTK" href="parsing_NLTK.html" />
    <link rel="prev" title="Markov Chains" href="markov_chain.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="text-generation-with-first-order-markov-chain">
<h1>Text Generation with First-Order Markov Chain<a class="headerlink" href="#text-generation-with-first-order-markov-chain" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://github.com/assamite/cc-mas16/blob/master/week1/toy_markov.py">(full code)</a></p>
<p>In this section we will show how a first-order Markov chain can be used as a
generative model. We start by creating the state transition probabilities for
an artificial dataset, and then generate text using these probabilities.</p>
<div class="section" id="generate-data">
<h2>Generate Data<a class="headerlink" href="#generate-data" title="Permalink to this headline">¶</a></h2>
<p>First, we need to generate some data. For this example we will use a very simple
model, where we first define a distribution as a string of characters, and then
draw from that distribution the target number of items concatenating them
to another string.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="n">dist</span> <span class="o">=</span> <span class="s1">&#39;Iä! Iä! Cthulhu for president!&#39;</span>
<span class="n">target</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">data</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="section" id="compute-state-transition-probabilities">
<h2>Compute State Transition Probabilities<a class="headerlink" href="#compute-state-transition-probabilities" title="Permalink to this headline">¶</a></h2>
<p>Next, our goal is to compute the state transition probabilities for the generated
data. In this example, each character in the generated string is a state and
subsequent pairs of characters represent state transitions. That is, a string
&#8216;abc&#8217; has two state transitions, from &#8216;a&#8217; to &#8216;b&#8217; and from &#8216;b&#8217; to &#8216;c&#8217;. (In
higher order Markov chains we would be interested in longer sequences of
characters, i.e. second-order Markov chain would have one state transition,
from &#8216;ab&#8217; to &#8216;bc&#8217;.)</p>
<p>State transition probabilities can be computed using nested dictionary as a
book-keeping data structure. The outer dictionary has the current (preceding)
state as a key, and the value of that key is another (inner) dictionary. The inner
dictionary has the succeeding states as keys and the values are the number of
times the succeeding state is observed after the preceding state. To populate
the data structure is quite forward, we go over the list of states one time,
and keep count of every predecessor-successor pair.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">transitions</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">succ</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">pred</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">transitions</span><span class="p">:</span>
        <span class="c1"># Predecessor key is not yet in the outer dictionary, so we create</span>
        <span class="c1"># a new dictionary for it.</span>
        <span class="n">transitions</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="n">succ</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">transitions</span><span class="p">[</span><span class="n">pred</span><span class="p">]:</span>
        <span class="c1"># Successor key is not yet in the inner dictionary, so we start</span>
        <span class="c1"># counting from one.</span>
        <span class="n">transitions</span><span class="p">[</span><span class="n">pred</span><span class="p">][</span><span class="n">succ</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Otherwise we just add one to the existing value.</span>
        <span class="n">transitions</span><span class="p">[</span><span class="n">pred</span><span class="p">][</span><span class="n">succ</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">1.0</span>
</pre></div>
</div>
<p>Now we have information about how many times each state has directly been
succeeded by other states. (Right now, we do not care if our state transitions
are not complete in the sense that zero counts are not marked in the data
structure, in many cases it is be justified to add a small transition
probability between all states that have zero transitions.) Next, we will sum
up every state&#8217;s total number of successors.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">totals</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">succ_counts</span> <span class="ow">in</span> <span class="n">transitions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">totals</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">succ_counts</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
</pre></div>
</div>
<p>Using <code class="docutils literal"><span class="pre">totals</span></code>, we can compute the probabilities for each state transition
by dividing each successor&#8217;s count for a state with the total number of
successors for that state:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">probs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">succ_counts</span> <span class="ow">in</span> <span class="n">transitions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">probs</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">succ</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">succ_counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">probs</span><span class="p">[</span><span class="n">pred</span><span class="p">][</span><span class="n">succ</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span> <span class="o">/</span> <span class="n">totals</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span>
</pre></div>
</div>
<p>In theory, we now have the state transition probabilities which could be used
to generate text. However, before doing that, we will convert the data
structure to a more usable form by representing the probabilities with a
cumulative distribution function ordered from highest to lowest probability.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">operator</span>
<span class="n">cdfs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">succ_probs</span> <span class="ow">in</span> <span class="n">probs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">items</span> <span class="o">=</span> <span class="n">succ_probs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="c1"># Sort the list by the second index in each item and reverse it from</span>
    <span class="c1"># highest to lowest.</span>
    <span class="n">sorted_items</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">operator</span><span class="o">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">cdf</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">cumulative_sum</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">sorted_items</span><span class="p">:</span>
        <span class="n">cumulative_sum</span> <span class="o">+=</span> <span class="n">prob</span>
        <span class="n">cdf</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">c</span><span class="p">,</span> <span class="n">cumulative_sum</span><span class="p">])</span>
    <span class="n">cdf</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># For possible rounding errors</span>
    <span class="n">cdfs</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span> <span class="o">=</span> <span class="n">cdf</span>
</pre></div>
</div>
</div>
<div class="section" id="generate-text">
<h2>Generate Text<a class="headerlink" href="#generate-text" title="Permalink to this headline">¶</a></h2>
<p>Finally, all that is left is to generate some text using our <code class="docutils literal"><span class="pre">cdfs</span></code> data
structure. We start by drawing a random character from the distribution, and
generate <em>N</em> characters overall. Then we loop generation loop until we have
generated enough items. In the generation loop, we will generate a random
number on each iteration and look from the cumulative distribution function of
<code class="docutils literal"><span class="pre">cdfs[state]</span></code> the appropriate successive state.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">markov_chain</span> <span class="o">=</span> <span class="n">start</span>

<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">markov_chain</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">:</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">markov_chain</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># Last element of the list</span>
    <span class="n">rnd</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="c1"># Random number from 0 to 1</span>
    <span class="n">cdf</span> <span class="o">=</span> <span class="n">cdfs</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span>
    <span class="n">cp</span> <span class="o">=</span> <span class="n">cdf</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Go through the cdf until the cumulative probability is higher than the</span>
    <span class="c1"># random number &#39;rnd&#39;.</span>
    <span class="k">while</span> <span class="n">rnd</span> <span class="o">&gt;</span> <span class="n">cp</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">cp</span> <span class="o">=</span> <span class="n">cdf</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">succ</span> <span class="o">=</span> <span class="n">cdf</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1">#print(rnd, succ, cdf)</span>
    <span class="n">markov_chain</span> <span class="o">+=</span> <span class="n">succ</span>

<span class="nb">print</span><span class="p">(</span><span class="n">markov_chain</span><span class="p">)</span>
</pre></div>
</div>
<p>That&#8217;s it. We have now computed the state transition probabilities from a toy
data set, and used them to generate new data. It is quite easy to alter this
example to also generate higher-order Markov chains, but that is left for the
future work!</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">CC-MAS 2016</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup.html">Setup Development Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="markov_chain.html">Markov Chains</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Text Generation with MC</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#generate-data">Generate Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#compute-state-transition-probabilities">Compute State Transition Probabilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="#generate-text">Generate Text</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="parsing_NLTK.html">Parsing Text with NLTK</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="markov_chain.html" title="previous chapter">Markov Chains</a></li>
      <li>Next: <a href="parsing_NLTK.html" title="next chapter">Parsing Text with NLTK</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Simo Linkola.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.8</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="_sources/toy_markov.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>